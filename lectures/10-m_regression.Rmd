---
title: 'Multiple Regression II'
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, rladies, rladies-fonts, "my-theme.css"]
    incremental: true
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r, echo=F, message=FALSE, warning=FALSE}
library(tidyverse)
```

## Last time...

* Model comparison
* Categorical predictors/dummy coding

--

### Today...

*ANOVA (the 611 version)

It's important to note that by covering dummy coding a categorical variable, we have already covered ANOVA -- there is nothing more you can learn from this technique that the omnibus test of that model will not tell you. 

---

## Example

Participants performed an eye-hand coordination task while subjected to periodic 3-second bursts of 85 dB white noise played over earphones. The task required participants to keep a mouse pointer on a red dot that moved in a circular motion at a rate of 1 revolution per second. Participants performed the task until they allowed the pointer to stray from the rotating dot 10 times.  The time (in seconds) at the 10th failure was recorded and is the outcome measure.

![](images/dot.jpg)
---

### Example

The participants were randomly assigned to one of four noise conditions:

* controllable and predictable noise
* uncontrollable but predictable noise
* controllable but unpredictable noise
* uncontrollable and unpredictable noise.

When noise was predictable, the 3-second bursts of noise would occur regularly every 20 seconds. 

When noise was unpredictable, the 3-second bursts would occur randomly (although every 20 seconds on average).  

---
When noise was uncontrollable, participants could do nothing to prevent the noise from occurring. 

When noise was  controllable, participants were shown a button that would prevent the noise, but they were told, "the button is a safety measure, for your protection, but we would prefer that you not use it unless absolutely necessary." No participants actually used the button.  

Why is it important that the button was never used?

Why is random assignment important in this design?

---

```{r, message = F}
library(here)
rotate = read.csv(here("data/pursuit_rotor.csv"))
head(rotate)
class(rotate$Group)
rotate$Group = as.factor(rotate$Group)
rotate$Group_lab = factor(rotate$Group, 
                          labels = c("Controllable\nPredictable", 
                                     "Uncontrollable\nPredictable",
                                     "Controllable\nUnpredictable",
                                     "Uncontrollable\nUnpredictable"))
```

---

```{r, warning=F, message=FALSE, fig.height=5, fig.width = 10}
ggpubr::ggboxplot(data = rotate, x = "Group_lab", y = "Time", xlab = F)
```

The pattern of means indicates that performance degrades with either uncontrollable noise or unpredictable noise. Noise that is both uncontrollable and unpredictable appears to be particularly disruptive.

---

```{r, fig.height=5, fig.width = 10}
ggpubr::ggbarplot(data = rotate, x = "Group_lab", y = "Time", xlab = F, add = c("mean_ci"), fill = "purple")
```

Addition of the confidence intervals indicates that the two extreme conditions are likely different from all of the other conditions.

---

```{r, warning = F, message = F, results = 'asis'}
library(knitr)
library(kableExtra)
rotate %>%
  group_by(Group_lab) %>%
  summarize(N = n(),
            Mean = mean(Time, na.rm = T),
            SD = sd(Time, na.rm = T)) %>%
  kable(., digits = 2) %>% kable_styling()
```

The groups differ in their sample sizes, which can easily occur with free random assignment.  There are advantages to equal sample sizes, so researchers often restrict random assignment to insure equal sample sizes across conditions.

Hard to tell if the variability in the four groups is homogeneous. 

---
### Hypothesis

Unlike regression, the ANOVA framework has a single hypothesis test. This is equivalent to the omnibus test of a multiple regression model.

.pull-left[
### Regression

$$H_0: \rho^2_{Y\hat{Y}} = 0$$
$$H_1: \rho^2_{Y\hat{Y}} > 0$$
]

.pull-left[
### ANOVA

$$H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4$$
$$H_1: \text{Not that } \mu_1 = \mu_2 = \mu_3 = \mu_4$$
This can occur in quite a number of ways.
]

---

The total variability of all of the data, regardless of group membership, can be expressed as:

$$\large Var(Y) = \frac{1}{N}\sum_{k=1}^G\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y})^2$$

for G groups and $ N_k $ participants within groups. 

In analysis of variance, we will be interested in the numerator of this variance equation, known as the total sum of squares:

$$\large SS_{tot} = \sum_{k=1}^G\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y})^2$$
It's worth noting that this is just a more complicated way of expressing total sums of squares, but in a way that will be useful for thinking about how we partition sums of squares later. 

---

We already know from regression that the deviation of a score from the grand mean is the sum of two independent parts. In regression these parts are the deviation of the actual score from the predicted score, and  the deviation of the predicted value from the grand mean. 

$$\large Y_{i}-\bar{Y} = (Y_{i}-\hat{Y}_i) + (\hat{Y} - \bar{Y}_i)$$

In ANOVA, this holds true, but we express these relationships by referring to each Y within a group, and instead of "predicted value" we talk about group means. So now the parts are the deviation of the score from its group mean, and the deviation of that group mean from the grand mean. Why do we substitute "group mean" for "predicted value"?

$$\large Y_{ik}-\bar{Y} = (Y_{ik}-\bar{Y}_k) + (\bar{Y}_k - \bar{Y})$$
--

In other words, each deviation score has a within-group part and a between-group part. These separate parts can be squared and summed, giving rise to two other sums of squares. 

---
One part, the within-groups sum of squares, represents squared deviations of scores around the group means:

$$\large SS_w = \sum_{k=1}^G\sum_{i=1}^{N_k}(Y_{ik}-\bar{Y}_k)^2$$
The other, the between-groups sum of squares, represents deviations of the group means around the grand mean:

$$\large SS_b = \sum_{k=1}^GN_k(\bar{Y}_{k}-\bar{Y})^2$$
How do these compare the sums of squares we are familiar with in regression?

---
Sums of squares are central to ANOVA.  They are the building blocks that represent different sources of variability in a research design. They are additive, meaning that the SStot can be partitioned, or divided, into independent parts.

The total sum of squares is the sum of the between-groups sum of squares and the within-groups sum of squares. 

$$\large SS_{tot} = SS_b + SS_w$$
The relative magnitude of sums of squares, especially in more complex designs, provides a way of identifying particularly large and important sources of variability.
---

If the null hypothesis is true, then variability among the means should be consistent with the variability of the data.

We know that relationship already:
$$\large \hat{\sigma}^2_{\bar{Y}} = \frac{\hat{\sigma}^2_{Y}}{N}$$
In other words, if we have an estimate of the variance of the means, we can transform that into an estimate of the variance of the scores, provided the only source of mean variability is sampling variability (the null hypothesis).

$$\large N\hat{\sigma}^2_{\bar{Y}} = \hat{\sigma}^2_Y$$
---

The $SS_w$ is qualitatively giving us information that is similar to 

$$\large \hat{\sigma}^2_Y$$
The $SS_b$ is qualitatively giving us information that is similar to 
$$\large N\hat{\sigma}^2_{\bar{Y}}$$

These are arrived at separately, but under the null hypothesis they should be estimates of the same thing.  The only reason that $SS_b$ would be larger than expected is if there are systematic differences among the mean, perhaps created by experimental manipulations.

We need a formal way to make the comparison.

---

Because the sums of squares are numerators of variance estimates, we can divide each by their respective degrees of freedom to get variance estimates that, under the null hypothesis, should be approximately the same.

These variance estimates are known as mean squares:
.pull-left[
$$\large MS_w = \frac{SS_w}{df_w}$$
$$\large df_w = N-G$$
]
.pull-right[
$$\large MS_b = \frac{SS_b}{df_b}$$
$$\large df_b = G-1$$
]

How are these degrees of freedom determined?

---


<!-- ## Group level multiple regression -->
<!-- - i.e., ANOVA models   -->
<!-- - Need to put numbers to our categories -->
<!-- - Dummy code is default -->
<!-- - Effect coding is an option -->
<!-- - Other types too (though most are unhelpful) -->

<!-- ```{r, echo = FALSE} -->
<!-- library(tidyverse) -->
<!-- library(forcats) -->
<!-- one.way <- read.csv("anova.csv") -->
<!-- one.way$group <- one.way$IV -->
<!-- one.way$group <- as.factor(one.way$group) -->
<!-- one.way <- one.way %>% -->
<!--   mutate(group = fct_recode(group, -->
<!--     "control"    = '0', -->
<!--     "tx1"    = '1', -->
<!--     "tx2"    = '2')) %>%  -->
<!--   as_tibble() -->

<!-- library (broom) -->
<!-- ``` -->

<!-- ## When working with factors -->
<!-- - know thy class -->
<!-- ```{r} -->
<!-- class(one.way$group) -->
<!-- table(one.way$group) -->
<!-- ``` -->
<!-- - Many base R functions automatically convert character vectors to factors -->
<!-- - This is okay if you are just tossing into a regression model but problematic for many uses -->


<!-- ## Group level multiple regression -->
<!-- ```{r} -->
<!-- model.1 <- lm(drugs ~ group, data = one.way )  -->
<!-- summary(model.1) -->
<!-- ``` -->

<!-- ## What happened?  -->

<!-- - For every nominal/categorical variable that has more than 2 levels R (default R) automatically creates L-1 dummy variables   -->

<!-- - Each of these dummy variables consists of 0 & 1s just like before, except 1 group (the reference group) only is coded as a zero -->

<!-- - The interpretation of each coefficent is the difference between the group coded 1 and the reference group -->

<!-- ## group means -->
<!-- ```{r, message=FALSE} -->
<!-- library(dplyr) -->
<!-- (one.way %>%  -->
<!--     group_by(group) %>%  -->
<!--     filter(!is.na(drugs)) %>%  -->
<!--     summarise(mean(drugs))) -->
<!-- ``` -->


<!-- ## See what R is doing with contrasts function -->
<!-- - a part of every factor  -->
<!-- ```{r} -->
<!-- contrasts(one.way$group) -->

<!-- # Can see the same with only 2 levels -->
<!-- contrasts(Multipleregression$group) -->
<!-- ``` -->

<!-- ## reordering -->
<!-- - no inherent order, so what does R spit out at you first?  -->
<!-- - default is alphabetic, but what if you wanted it by another variable -->

<!-- ```{r} -->
<!-- levels(one.way$group) -->
<!-- one.way$group.2 <- relevel(one.way$group, "tx2") -->
<!-- levels(one.way$group.2) -->
<!-- ``` -->

<!-- ##  -->
<!-- ```{r} -->
<!-- model.2 <- lm(drugs ~ group.2, data = one.way )  -->
<!-- tidy(summary(model.2)) -->
<!-- contrasts(one.way$group.2) -->
<!-- ``` -->


<!-- ## contrasts -->
<!-- ```{r} -->
<!-- ## dummy variables via: -->
<!-- contr.treatment(4) -->
<!-- ## effect coding via:  -->
<!-- contr.sum(4) -->
<!-- ``` -->

<!-- ## Asign contrast to factor variable -->

<!-- ```{r} -->
<!-- contr.sum(3) -->
<!-- contrasts(one.way$group) <- contr.sum(3) -->
<!-- model.3 <- lm(drugs ~ group, data = one.way )  -->
<!-- tidy(model.3) -->
<!-- ``` -->
<!-- ## effects (sum) coding -->
<!-- - note: intercept is the means of means -->
<!-- ```{r} -->
<!-- library(psych) -->
<!-- describe(one.way$drugs) -->
<!-- table(one.way$group) -->
<!-- ``` -->
<!-- - you may want to do "weighted" effect coding -->

<!-- ##  -->
<!-- ```{r} -->
<!-- anova(model.3) -->
<!-- ``` -->
<!--  - What does the ANOVA table look like for model.1 and model.2?  -->
<!--  - note the df for SSregression/SSbetween -->


<!-- ## what happens if you want a different reference group?  -->
<!-- - in addition to relevel (and fct_relevel in forcats) you can change the contrast matrix -->
<!-- ```{r} -->
<!-- contrasts(one.way$group) <- contr.treatment(3, base = 2) -->
<!-- model.4 <- lm(drugs ~ group, data = one.way )  -->
<!-- tidy(model.4) -->
<!-- ``` -->

<!-- ## -->

<!-- ```{r} -->
<!-- contrasts(one.way$group) <- contr.treatment(3, base = 3) -->
<!-- model.5 <- lm(drugs ~ group, data = one.way )  -->
<!-- tidy(model.5) -->
<!-- ``` -->


<!-- ## What happens if you have both nominal and continuous variables in the same model?  -->

<!-- ```{r} -->
<!-- model.6 <- lm(drugs ~ group + alcohol, data = one.way )  -->
<!-- tidy(model.6) -->
<!-- ``` -->

<!-- ## how should you code variables to begin with? -->

<!-- - Easy enough to work with factor variables that have their level as their name -->
<!-- - No need to manually change (or create) a number associated with a level and use as.numeric -->
<!-- - For simple dichotomous variables, sometimes people do code 0/1 rather than tx/control for example -->
<!-- - Information could be lost without a code book, so best to name the variable what is coded 1 (e.g., tx or female rather than group or gender) -->


