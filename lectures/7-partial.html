<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Partial correlations</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.4/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Partial correlations

---


## Business

Homework assignment #2 has been posted. It's due next Friday. 

Thursday: HW breakout groups

Supplemental reading [posted](https://uopsych.github.io/psy612/bonus.html) (Cohen et al).

---
## Today

- path diagrams
- partial and semi-partial correlations

---

## Causal relationships

Does parent socioeconomic status *cause* better grades?

  * `\(r_{\text{GPA},\text{SES}} = .33\)`
  
--

Potential confound: Peer relationships

   - `\(r_{\text{SES}, \text{peer}} = .29\)`
   - `\(r_{\text{GPA}, \text{peer}} = .37\)`

???

Don't know how variables are related, only know that they are

in a perfect world, we would want to **hold constant** peer relationships
- control for
- partial out

---
### Does parent SES cause better grades?

![](images/path/Slide1.jpeg)
---
### spurious relationship

![](images/path/Slide2.jpeg)


---
### indirect (mediation)

![](images/path/Slide3.jpeg)


---
### interaction (moderation)

![](images/path/Slide4.jpeg)


---
### multiple causes

![](images/path/Slide5.jpeg)


---
### direct and indirect effects

![](images/path/Slide6.jpeg)


---
### multiple regression

![](images/path/Slide7.jpeg)
---
## General regression model


`$$\large \hat{Y} = b_0 + b_1X_1 + b_2X_2 + \dots+b_kX_k$$`

This is ultimately where we want to go. Unfortunately, it's not as simply as multiplying the correlation between Y and each X by the ratio of their standard errors and stringing them together. 

Why?

---

## What is `\(R^2\)`?

.pull-left[
![](images/venn/Slide1.jpeg)
]
.pull-right[
`$$\large R^2 = \frac{s^2_{\hat{Y}}}{s^2_Y}$$`
`$$\large = \frac{SS_{\text{Regression}}}{SS_Y}$$`
]

---
![](images/venn/Slide2.jpeg)

### What is `\(R^2\)`?

---

![](images/path/Slide5.jpeg)

---

![](images/path/Slide7.jpeg)

---

### What is `\(R^2\)`?

![](images/venn/Slide3.jpeg)
---

### Types of correlations

Pearson product moment correlation
- Zero-order correlation
- Only two variables are X and Y

--

Semi-partial correlation
- This correlation assess the extent to which the part of `\(X_1\)` *that is independent of* of `\(X_2\)` correlates with all of Y
- This is often the estimate that we refer to when we talk about **controlling for** another variable.

---

![](images/venn/Slide4.jpeg)

???

the semi-partial correlation between parent SES and GPA controlling for peer relationships is a (not c), divided by all of GPA

---
### Semi-partial correlations

`$$\large sr_1 = r_{Y(1.2)} = \frac{r_{Y1}-r_{Y2}r_{12}}{\sqrt{1-r^2_{12}}}$$`

`$$\large sr_1^2 = R^2_{Y.12}-r^2_{Y2}$$`

**Terms**

`\(R_{Y.12}\)` -- The correlation of Y with the (best) linear combination of X1 and X2.

`\(r_{Y(1.2)}\)` -- the semi-partial correlation of Y with X1 controlling for X2



---

### Types of correlations

Pearson product moment correlation
- Zero-order correlation
- Only two variables are X and Y

Semi-partial correlation
- This correlation assess the extent to which the part of `\(X_1\)` *that is independent of* of `\(X_2\)` correlates with all of Y
- This is often the estimate that we refer to when we talk about **controlling for** another variable.

--

Partial correlation
- The extent to which the part of X1 that is independent of X2 is correlated with the part of Y that is also independent of X2. 
---

![](images/venn/Slide5.jpeg)
---

![](images/venn/Slide6.jpeg)
---
### Partial correlations

`$$\large pr_1=r_{Y1.2} = \frac{r_{Y1}-r_{Y2}r_{{12}}}{\sqrt{1-r^2_{Y2}}\sqrt{1-r^2_{12}}} = \frac{r_{Y(1.2)}}{\sqrt{1-r^2_{Y2}}}$$`

**Terms**

`\(R_{Y.12}\)` -- The correlation of Y with the (best) linear combination of X1 and X2.

`\(r_{Y(1.2)}\)` -- the semi-partial correlation of Y with X1 controlling for X2

`\(r_{Y1.2}\)` -- the partial correlation of Y with X1 controlling for X2
---

### What happens if X1 and X2 are uncorrelated?

How does the semi-partial correlation compare to the zero-order correlation?

--

`$$\large r_{Y(1.2)} = r_{Y1}$$`

How does the partial correlation compare to the zero-order correlation?

--

`$$\large r_{Y1.2} \neq r_{Y1}$$`


---

## When we use these?

The semi-partial correlation is most often used when we want to show that some variable adds incremental variance in Y above and beyond another X variable.

- e.g., predicting Alzheimer's

The partial correlations most often used when some third variable, Z, is a plausible explanation of the correlation between X and Y

- e.g., predicting grades

---

## Example

Recall the expertise dataset, which measures a person's perception of their knowledge of personal finance (`self_perceived_knowledge`) and their performance on an objective measures of knowledge (`overclaiming_perception`). 

Participants also completed a test called the FINRA, which is an actual financial literacy test. 


```r
library(here)
expertise = read.csv(here("data/expertise.csv"))
```

---


```r
round(cor(expertise[,c("self_perceived_knowledge", "overclaiming_proportion", "FINRA_score")]),2)
```

```
##                          self_perceived_knowledge overclaiming_proportion
## self_perceived_knowledge                     1.00                    0.48
## overclaiming_proportion                      0.48                    1.00
## FINRA_score                                  0.32                   -0.04
##                          FINRA_score
## self_perceived_knowledge        0.32
## overclaiming_proportion        -0.04
## FINRA_score                     1.00
```

```r
library(ppcor)

spcor.test(expertise$overclaiming_proportion,  # Y
           expertise$self_perceived_knowledge, # X1
           expertise$FINRA_score)              # X2
```

```
##    estimate     p.value statistic   n gp  Method
## 1 0.5201425 2.50243e-15  8.591136 202  1 pearson
```

---


```r
round(cor(expertise[,c("self_perceived_knowledge", "overclaiming_proportion", "FINRA_score")]),2)
```

```
##                          self_perceived_knowledge overclaiming_proportion
## self_perceived_knowledge                     1.00                    0.48
## overclaiming_proportion                      0.48                    1.00
## FINRA_score                                  0.32                   -0.04
##                          FINRA_score
## self_perceived_knowledge        0.32
## overclaiming_proportion        -0.04
## FINRA_score                     1.00
```

```r
library(ppcor)

pcor.test( expertise$overclaiming_proportion,  # Y
           expertise$self_perceived_knowledge, # X1
           expertise$FINRA_score)              # X2
```

```
##    estimate      p.value statistic   n gp  Method
## 1 0.5205143 2.372099e-15  8.599559 202  1 pearson
```


---

## Regression

Recall that the residuals of a univariate regression equation are the part of the outcome `\((Y)\)` that is independent of the predictor `\((X)\)`.

`$$\Large \hat{Y} = b_0 + b_1X$$`
`$$\Large e_i = Y_i - \hat{Y_i}$$`
We can use this to construct a measure of `\(X_1\)` that is independent of `\(X_2\)`:

`$$\Large \hat{X}_{1.2} = b_0 + b_1X_2$$`

`$$\Large e_{X_1} = X_1 - \hat{X}_{1.2}$$`

---

We can either correlate that value with Y, to calculate our semi-partial correlation:

`$$\Large r_{e_{X_1},Y} = r_{Y(1.2)}$$`

Or we can calculate a measure of Y that is also independent of `\(X_2\)` and correlate that with our `\(X_1\)` residuals.

`$$\Large \hat{Y} = b_0 + b_1X_2$$`

`$$\Large e_{Y} = Y - \hat{Y}$$`

`$$\Large r_{e_{X_1},e_{Y}} = r_{Y1.2}$$`

---

### Example


```r
# create measure of overclaiming independent of FINRA score
mod.over = lm(overclaiming_proportion ~ FINRA_score, data = expertise)
expertise.over = broom::augment(mod.over)

# create measure of perceived knowledge independent of FINRA score
mod.know = lm(self_perceived_knowledge ~ FINRA_score, data = expertise)
expertise.know = broom::augment(mod.know)


#semi-partial
cor(expertise.over$.resid, expertise$self_perceived_knowledge)
```

```
## [1] 0.4935161
```

```r
#partial
cor(expertise.over$.resid, expertise.know$.resid)
```

```
## [1] 0.5205143
```

---

class: inverse

## Next time...

Multiple regression!!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
