---
title: "Lab 3: Univariate Regression (cont.) & GLM"
output: 
  html_document: 
    fig_caption: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: TRUE
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, rows.print = 10)

# suppress scientific notation
options(scipen = 999)
```


# Purpose

INTRO 

To quickly navigate to the desired section, click one of the following links:

1. [Uncertainty in regression](#uncertainty)

You will need to load the following libraries to follow along with today's lab. If you don't have any of these packages installed, please do so now. 

```{r message=FALSE}
library(tidyverse) # for plotting and data wrangling
library(rio) # for importing data
library(psych) # for stats functions
library(broom) # for cleaning up output
```

***

# Uncertainty in regression{#uncertainty}


## Data and review

```{r}
health <- import("https://raw.githubusercontent.com/uopsych/psy612/master/labs/lab-3/data/consc_health.csv")
```
<br>

* Here's how we wrote out our model

$$Y_i = \beta_0 + \beta_1X_i + \epsilon_i$$

$$health_i = \beta_0 + \beta_1consc_i + \epsilon_i$$
<br>

* Here's how we specified the model in R

```{r}
model <- lm(sr_health ~ consc, data = health)
```
<br>

* Here are our cofficients...

```{r echo=FALSE}
tidy(model) %>% #
  rename(coefficient = term,
        b = estimate,
        SE = std.error,
        t = statistic,
        p = p.value) %>%
  mutate(p = ifelse(p > .001, round(p, 3), "< .001")) %>% 
  knitr::kable(digits = c(NA, 2, 2, 2, 3), 
               caption = "Results of Regressing Self-Reported Health on Conscientiousness") 
```
<br>

> **Question:** What do the intercept and slope mean? What do the *t*-values tell us? 

> **Answer:** Intercept = the expected value for self-rated health when conscientiousness is 0. Slope = the magnitude of the relationship between conscientiousness and self-rated health: for every 1-unit increase in conscientiousness, we expect a 0.49-unit increase in self-rated health. *t*-values are from a one-sample t-test assessing whether the slope and intercept are significantly different from 0; the *t* values represent the ratio of signal to noise (i.e. each b divided by its standard error).

## Confidence intervals

* Our `b's` (intercept and slope) are *estimates* from our sample of true population parameters ($\beta$'s). Remember that whenever we calculate an estimate of something, we should also determine how precise our estimate is. This is where standard errors and confidence intervals come in. 

* Recall the formula for calculating confidence intervals:

$$CI_b = b \pm CV(SE_b)$$

* In [Minihack 1](#minihack1) you will get some practice using this formula to calculate confidence intervals around regression coefficients. For now, we will use a much easier method: `stats::confint()`. This function takes in a fitted model object as the first argument. By default it will give you 95% CI's. 

```{r }
confint(model)
```

>**Question:** What does these 95% CI for the slope of conscientiousness mean in plain English? 

>**Answer:** If we were to repeat this experiment over and over again, sampling from the same population, 95% of the time the slope we calculate would be between 0.25 and 0.73 (i.e. in 19 out of every 20 experiments we'd get a slope in this interval).

## Confidence bands

* In addition to estimating precision around the our coefficients, we can also estimate our precision around each predicted values, $\hat{Y_i}$. These standard errors are generated by `broom::augment()` (and are labeled `se.fit`).

```{r}
model %>% # start with our model object
  augment() %>% # from broom package; gives us fitted values, residuals, etc.
  select(sr_health, .fitted, .se.fit) # select relevant variables
```
<br>

* If we were to string all of this information together, it would generate a confidence **band** around our regression line. As we've seen already several times, it's really easy to get this confidence band when creating a scatter plot by adding `geom_smooth(method = "lm")`. 


```{r}
health %>%
  ggplot(aes(x = consc, y = sr_health)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(method = "lm") +
  scale_x_continuous("Conscientiousness") +
  scale_y_continuous("Self-rated health") +
  theme_minimal()
```



<!-- ```{r echo=FALSE} -->
<!-- coef_ci <- confint(model) -->

<!-- health %>% -->
<!--   ggplot(aes(x = consc, y = sr_health)) + -->
<!--   geom_point(alpha = 0.3) + -->
<!--   geom_smooth(method = "lm") + -->
<!--   geom_abline(aes(intercept = coef_ci[1,1], slope = coef_ci[2,2])) + -->
<!--   geom_abline(aes(intercept = coef_ci[1,2], slope = coef_ci[2,1])) + -->
<!--   scale_x_continuous("Conscientiousness") + -->
<!--   scale_y_continuous("Self-rated health") + -->
<!--   theme_minimal() -->
<!-- ``` -->
<!-- <br> -->



* Animated demo

```{r echo=FALSE}
library(ungeviz)
library(gganimate)
library(transformr)
library(gifski)

set.seed(012220)

boots <- bootstrapper(50)

p <- health %>%
  ggplot(aes(x = consc, y = sr_health)) +
  geom_smooth(method = "lm", color = NA) +
  geom_point(alpha = 0.3) +
  geom_point(data = boots, aes(group = .row)) +
  geom_smooth(data = boots, method = "lm", fullrange = TRUE, se = FALSE) +
  theme_minimal() +
  scale_x_continuous("Conscientiousness") +
  scale_y_continuous("Self-rated health") +
  transition_states(.draw, 1, 1) +
  enter_fade() +
  exit_fade() +
  ease_aes()

animate(p, fps = 3)

```
<br>


## Prediction bands



***

# Regression with matrix algebra

***

# The General Linear Model

***



***

# Minihacks

## Minihack 1: Calculating confidence intervals{#minihack1}

1. Calculating confidence intervals "by hand". 

```{r}
model_summary <- summary(model)

# extract coefficients
int <- model_summary$coefficients[[1,1]]
slope <- model_summary$coefficients[[2,1]]

# extract standard errors of coefficients
int_se <- model_summary$coefficients[[1,2]]
slope_se <- model_summary$coefficients[[2,2]]

# df for t-distribution (will be denominator df from F statistic)
df <- model_summary$fstatistic[["dendf"]]

# intercept 95% CI 
int_ci_l <- int - qt(.975, df = df)*int_se
int_ci_u <- int + qt(.975, df = df)*int_se

# slope 95% CI 
slope_ci_l <- slope - qt(.975, df = df)*slope_se
slope_ci_u <- slope + qt(.975, df = df)*slope_se
```

2. Verify that your answer corresponds to the result from `confint()`. 

```{r}
confint(model)
```


***

## Minihack 2

***

## Minihack 3

***
